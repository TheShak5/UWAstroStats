{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this example, we show you how to run an MCMC using the emulator derived in the previous assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this you need to install emcee: https://emcee.readthedocs.io/en/stable/user/install/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\patel\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from cosmopower_NN import cosmopower_NN\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: load the emulator with its rescaling, one reference model we have not trained on, the corresponding parameters, and the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\patel\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reference_index  = [8000]\n",
    "\n",
    "parameters = np.load('data_4_assignment2/parameters.npz')\n",
    "reference_params = {}\n",
    "for name in parameters.keys():\n",
    "    reference_params[name]=list(np.array(parameters[name])[reference_index])\n",
    "  \n",
    "models = np.load('data_4_assignment2/models.npy')   \n",
    "reference_model = np.load('data_4_assignment2/models.npy')[reference_index][0]\n",
    "\n",
    "\n",
    "cov=np.load('data_4_assignment1/covariance.npy')\n",
    "cov_inv = inv(cov)\n",
    "\n",
    "cp_nn_model = cosmopower_NN(restore=True, restore_filename='data_4_assignment3/emulator_final')\n",
    "\n",
    "\n",
    "train_sample = np.arange(0,7000)\n",
    "train_features = np.load('data_4_assignment2/models.npy')[train_sample]\n",
    "minimum=np.min(train_features,axis=0)\n",
    "maximum=np.max(train_features-minimum,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will show you a example MCMC. Try to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.4\n"
     ]
    }
   ],
   "source": [
    "import emcee\n",
    "import multiprocess as mp\n",
    "import os \n",
    "\n",
    "total_steps = 2000 # total  number of steps each walker is doing\n",
    "burning_steps = 1000 # how many buring steps you want to remove\n",
    "nwalkers = 50 # Number of walkers that probe the parameter space\n",
    "\n",
    "num_threads = 10 # number of cpu cores to use\n",
    "\n",
    "#which paramters we want to vary\n",
    "parameters = np.load('data_4_assignment2/parameters.npz')\n",
    "param_names_varying = ['omega_m', 'As'] # alternatively you can also just use parameters.files\n",
    "ndim = len(param_names_varying)\n",
    "\n",
    "\n",
    "## a function that distributed start postions inside the trained parameters\n",
    "def start_position_lh_and_step_size(seed):\n",
    "    random.seed(seed)\n",
    "    p0 = []\n",
    "    for i in range(nwalkers):\n",
    "        random_starts = []\n",
    "        \n",
    "        for name in param_names_varying:\n",
    "            lower_edge = np.min(parameters[name])\n",
    "            upper_edge = np.max(parameters[name])\n",
    "            if(lower_edge<0):\n",
    "                lower_edge = lower_edge * 0.99\n",
    "            else:\n",
    "                lower_edge = lower_edge * 1.01\n",
    "            if(upper_edge>0):\n",
    "                upper_edge = upper_edge * 0.99\n",
    "            else:\n",
    "                upper_edge = upper_edge * 1.01     \n",
    "                \n",
    "            random_starts.append(random.uniform(lower_edge,upper_edge))\n",
    "\n",
    "        p0.append(random_starts)\n",
    "        \n",
    "    return np.array(p0)\n",
    "\n",
    "## function that computes our priors. Here we only allow the walker to be inside the training range. You can also define Gaussian priors. \n",
    "def cal_logprior(para_dict):\n",
    "\n",
    "    lnprior = 0\n",
    "    #cosmological priors\n",
    "    for name in param_names_varying:\n",
    "        if(para_dict[name]>np.max(parameters[name])):\n",
    "            lnprior = -np.inf\n",
    "        if(para_dict[name]<np.min(parameters[name])):\n",
    "            lnprior = -np.inf\n",
    "    \n",
    "    return lnprior\n",
    "\n",
    "## Function that computes the likelihood\n",
    "def calc_likelihood(para):\n",
    "    \n",
    "    params = {'omega_b':reference_params['omega_b'],'w':reference_params['w']}\n",
    "    for i in range(len(param_names_varying)):\n",
    "        params[param_names_varying[i]] = [para[i]]\n",
    "\n",
    "    # print(params)\n",
    "\n",
    "    pred_vector = cp_nn_model.predictions_np(params)[0]\n",
    "    pred_vector = pred_vector*maximum+minimum \n",
    "    \n",
    "    # print(pred_vector.shape,reference_model.shape,cov_inv.shape)\n",
    "    \n",
    "    delta = pred_vector - reference_model\n",
    "    likelihood = -0.5*np.matmul(delta,np.matmul(cov_inv,delta))\n",
    "\n",
    "    lnprior = cal_logprior(para_dict=params)\n",
    "\n",
    "    return likelihood+lnprior\n",
    "\n",
    "\n",
    "\n",
    "print(emcee.__version__)\n",
    "p0 = start_position_lh_and_step_size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, calc_likelihood)\n",
    "sampler.run_mcmc(p0, total_steps, progress=True)\n",
    "\n",
    "samples_emcee = sampler.get_chain(discard=burning_steps,flat=True)\n",
    "np.save('data_4_assignment3/outputs_MCMC/MCMC_test_emcee',samples_emcee)\n",
    "log_prob_samples = sampler.get_log_prob(discard=burning_steps, flat=True)\n",
    "np.save('data_4_assignment3/outputs_MCMC/logp_test_emcee',log_prob_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples_emcee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     para_priors_low[name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(parameters[name])\n\u001b[0;32m     16\u001b[0m     para_priors_up[name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(parameters[name])\n\u001b[1;32m---> 19\u001b[0m samples_getdist \u001b[38;5;241m=\u001b[39m MCSamples(samples\u001b[38;5;241m=\u001b[39m\u001b[43msamples_emcee\u001b[49m,names \u001b[38;5;241m=\u001b[39m para_names, ranges \u001b[38;5;241m=\u001b[39m para_priors, settings\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmooth_scale_2D\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmooth_scale_1D\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.3\u001b[39m})\n\u001b[0;32m     22\u001b[0m colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightcoral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroyalblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m bright \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#4477AA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#EE6677\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#228833\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#CCBB44\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#66CCEE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#AA3377\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#BBBBBB\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'samples_emcee' is not defined"
     ]
    }
   ],
   "source": [
    "from getdist import plots, MCSamples, parampriors\n",
    "import getdist\n",
    "\n",
    "\n",
    "para_names =np.array(['omega_m', 'omega_b', 'As', 'w'])[[0,2]]\n",
    "param_names_latex = [r'$\\Omega_\\mathrm{m}$', r'$\\Omega_\\mathrm{b}$', r'$A_\\mathrm{s}$',r'$w$']\n",
    "\n",
    "parameters = np.load('data_4_assignment2/parameters.npz')\n",
    "parameters.keys()\n",
    "para_priors = {}\n",
    "para_priors_low = {}\n",
    "para_priors_up = {}\n",
    "for name in para_names:\n",
    "    para_priors[name] = [np.min(parameters[name]),np.max(parameters[name])]\n",
    "    para_priors_low[name] = np.min(parameters[name])\n",
    "    para_priors_up[name] = np.max(parameters[name])\n",
    "\n",
    "\n",
    "samples_getdist = MCSamples(samples=samples_emcee,names = para_names, ranges = para_priors, settings={'smooth_scale_2D': 0.3, 'smooth_scale_1D': 0.3})\n",
    "\n",
    "\n",
    "colors = ['lightcoral', 'royalblue', 'orange']\n",
    "bright = ['#4477AA', '#EE6677', '#228833', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB']\n",
    "retro = ['#4165c0', '#e770a2', '#5ac3be', '#696969', '#f79a1e', '#ba7dcd']\n",
    "\n",
    "g = plots.get_subplot_plotter(width_inch=12)\n",
    "g.settings.axis_marker_lw = 1.0\n",
    "g.settings.axis_marker_ls = '-'\n",
    "g.settings.title_limit_labels = False\n",
    "g.settings.axis_marker_color = 'k'\n",
    "g.settings.legend_colored_text = True\n",
    "g.settings.figure_legend_frame = False\n",
    "g.settings.linewidth = 2.0\n",
    "g.settings.linewidth_contour = 3.0\n",
    "g.settings.legend_fontsize = 22\n",
    "g.settings.axes_fontsize = 17\n",
    "g.settings.axes_labelsize = 22\n",
    "g.settings.axis_tick_x_rotation = 45\n",
    "g.settings.axis_tick_max_labels = 6\n",
    "g.settings.solid_colors = retro\n",
    "\n",
    "priors = parampriors.ParamBounds()\n",
    "# priors.names = para_names\n",
    "# priors.lower = para_priors_low\n",
    "# priors.upper = para_priors_up\n",
    "\n",
    "g.triangle_plot(\n",
    "    roots=[samples_getdist],\n",
    "    filled=True,\n",
    "    legend_loc='upper right',\n",
    "    legend_labels = ['test'],\n",
    "    title_limit=1,\n",
    "    # upper_roots=[1,2,0],\n",
    "    # param_limits=para_priors,\n",
    "    markers=reference_params,\n",
    ")\n",
    "\n",
    "plt.savefig('plots_4_assignment3/MCMC_test.jpg',dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2=-2*np.load('data_4_assignment3/outputs_MCMC/logp_test_emcee.npy')[0]\n",
    "plt.hist(chi2,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_24032\\2130210248.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "using cpu device \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import affine_new as affine\n",
    "\n",
    "\n",
    "# checking that we are using a GPU\n",
    "device = 'gpu:0' if tf.test.is_gpu_available() else 'cpu'\n",
    "device='cpu'\n",
    "print('using', device, 'device \\n')\n",
    " \n",
    "total_steps = 2000\n",
    "burnin_steps = 1000\n",
    "nwalkers = 30\n",
    "\n",
    "parameters = np.load('data_4_assignment2/parameters.npz')\n",
    "param_names_varying = ['omega_m', 'As'] # alternatively you can also just use parameters.files\n",
    "ndim = len(param_names_varying)\n",
    "\n",
    "param_names_varying = ['omega_m', 'As']\n",
    "\n",
    "param_fixing = {}\n",
    "for name in ['omega_m','omega_b', 'As', 'w']:\n",
    "    if(name in param_names_varying):\n",
    "        continue\n",
    "    else:  \n",
    "        param_fixing[name] = reference_params[name]\n",
    "\n",
    "\n",
    "def start_position_lh_and_step_size(seed):\n",
    "    random.seed(seed)\n",
    "    p0 = []\n",
    "    for i in range(nwalkers):\n",
    "        random_starts = []\n",
    "        \n",
    "        for name in param_names_varying:\n",
    "            lower_edge = np.min(parameters[name])\n",
    "            upper_edge = np.max(parameters[name])\n",
    "            if(lower_edge<0):\n",
    "                lower_edge = lower_edge * 0.99\n",
    "            else:\n",
    "                lower_edge = lower_edge * 1.01\n",
    "            if(upper_edge>0):\n",
    "                upper_edge = upper_edge * 0.99\n",
    "            else:\n",
    "                upper_edge = upper_edge * 1.01     \n",
    "                \n",
    "            random_starts.append(random.uniform(lower_edge,upper_edge))\n",
    "            # random_starts.append(np.random.normal(fid_params[name], 0.00001)[0])\n",
    "        p0.append(random_starts)\n",
    "        \n",
    "    p0 = np.array(p0).astype(np.float32)\n",
    "    return tf.convert_to_tensor(p0)\n",
    "\n",
    "def from_parameters_tensor_to_table(parameters_tensor):\n",
    "\n",
    "    training_parameters_names = param_names_varying\n",
    "    \n",
    "    parameters_values = tf.transpose(parameters_tensor)\n",
    "    parameters_table = tf.lookup.experimental.DenseHashTable(key_dtype=tf.string, \n",
    "                                                                value_dtype=tf.float32, \n",
    "                                                                empty_key=\"<EMPTY_SENTINEL>\", \n",
    "                                                                deleted_key=\"<DELETE_SENTINEL>\", \n",
    "                                                                default_value=tf.zeros([parameters_tensor.shape[0]]))\n",
    "    parameters_table.insert(training_parameters_names, parameters_values)\n",
    "    return parameters_table\n",
    "\n",
    "# @tf.function\n",
    "def cal_logprior(cosmo_para_table,size):\n",
    "\n",
    "    lnprior = tf.zeros(size)\n",
    "    #cosmological priors\n",
    "    for name in param_names_varying:\n",
    "        lnprior=lnprior+tf.where(cosmo_para_table.lookup(name)<np.min(parameters[name]),-np.inf,lnprior)\n",
    "        lnprior=lnprior+tf.where(cosmo_para_table.lookup(name)>np.max(parameters[name]),-np.inf,lnprior)\n",
    " \n",
    "    return lnprior\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def calc_likelihood_tf(cosmo_para):\n",
    "    cosmo_para_table = from_parameters_tensor_to_table(cosmo_para)\n",
    "    for name in param_fixing.keys():\n",
    "        cosmo_para_table.insert(name, param_fixing[name]*tf.ones(cosmo_para.shape[0]))\n",
    "        \n",
    "    pred_vector = cp_nn_model.predictions_tf(tf.transpose(cosmo_para_table.lookup(tf.constant(cp_nn_model.parameters))))\n",
    "    pred_vector = tf.add(tf.multiply(pred_vector, maximum), minimum)\n",
    "    pred_vector = tf.cast(pred_vector, dtype=tf.float64)\n",
    "\n",
    "\n",
    "    diff_vec = tf.cast(tf.subtract(reference_model, pred_vector), dtype=tf.float64)\n",
    "    chi2 = tf.cast(tf.linalg.diag_part(tf.matmul(diff_vec, tf.matmul(cov_inv, tf.transpose(diff_vec)))), dtype=tf.float32)\n",
    "    likelihood =  -0.5 * chi2\n",
    "\n",
    "    log_prior = cal_logprior(cosmo_para_table,cosmo_para.shape[0])\n",
    "    likelihood = tf.add(likelihood, log_prior)\n",
    "    \n",
    "    return likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 451/1999 [00:20<01:06, 23.35it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "p0 = start_position_lh_and_step_size(0)\n",
    "p1 = start_position_lh_and_step_size(1)\n",
    "\n",
    "with tf.device(device):\n",
    "    chain,logp_chain = affine.affine_sample(calc_likelihood_tf, total_steps, [p0, p1], args=[])\n",
    "samples = chain.numpy()[burnin_steps:,:,:].reshape((-1, p0.shape[1]))\n",
    "logp_samples = logp_chain.numpy()[burnin_steps:,:].reshape((-1, 1)).T\n",
    "\n",
    "\n",
    "np.save('data_4_asssignment3/outputs_MCMC/MCMC_test_tf',samples)\n",
    "np.save('data_4_asssignment3/outputs_MCMC/logp_test_tf',logp_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdist import plots, MCSamples, parampriors\n",
    "import getdist\n",
    "\n",
    "\n",
    "para_names =np.array(['omega_m', 'omega_b', 'As', 'w'])[[0,2]]\n",
    "param_names_latex = [r'$\\Omega_\\mathrm{m}$', r'$\\Omega_\\mathrm{b}$', r'$A_\\mathrm{s}$',r'$w$']\n",
    "\n",
    "\n",
    "parameters = np.load('data_4_assignment2/parameters.npz')\n",
    "parameters.keys()\n",
    "para_priors = {}\n",
    "para_priors_low = {}\n",
    "para_priors_up = {}\n",
    "for name in para_names:\n",
    "    para_priors[name] = [np.min(parameters[name]),np.max(parameters[name])]\n",
    "    para_priors_low[name] = np.min(parameters[name])\n",
    "    para_priors_up[name] = np.max(parameters[name])\n",
    "\n",
    "\n",
    "samples_getdist = MCSamples(samples=samples,names = para_names, ranges = para_priors, settings={'smooth_scale_2D': 0.3, 'smooth_scale_1D': 0.3})\n",
    "\n",
    "\n",
    "colors = ['lightcoral', 'royalblue', 'orange']\n",
    "bright = ['#4477AA', '#EE6677', '#228833', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB']\n",
    "retro = ['#4165c0', '#e770a2', '#5ac3be', '#696969', '#f79a1e', '#ba7dcd']\n",
    "\n",
    "g = plots.get_subplot_plotter(width_inch=12)\n",
    "g.settings.axis_marker_lw = 1.0\n",
    "g.settings.axis_marker_ls = '-'\n",
    "g.settings.title_limit_labels = False\n",
    "g.settings.axis_marker_color = 'k'\n",
    "g.settings.legend_colored_text = True\n",
    "g.settings.figure_legend_frame = False\n",
    "g.settings.linewidth = 2.0\n",
    "g.settings.linewidth_contour = 3.0\n",
    "g.settings.legend_fontsize = 22\n",
    "g.settings.axes_fontsize = 17\n",
    "g.settings.axes_labelsize = 22\n",
    "g.settings.axis_tick_x_rotation = 45\n",
    "g.settings.axis_tick_max_labels = 6\n",
    "g.settings.solid_colors = retro\n",
    "\n",
    "priors = parampriors.ParamBounds()\n",
    "priors.names = para_names\n",
    "priors.lower = para_priors_low\n",
    "priors.upper = para_priors_up\n",
    "\n",
    "g.triangle_plot(\n",
    "    roots=[samples_getdist],\n",
    "    filled=True,\n",
    "    legend_loc='upper right',\n",
    "    legend_labels = ['test'],\n",
    "    title_limit=1,\n",
    "    # upper_roots=[1,2,0],\n",
    "    # param_limits=para_priors,\n",
    "    markers=reference_params,\n",
    ")\n",
    "\n",
    "plt.savefig('plots/MCMC_test.jpg',dpi=400, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2=-2*np.load('logp_test_tf.npy')[0]\n",
    "plt.hist(chi2,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
